{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rolling_App1.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrederikKober/Thesis/blob/main/Rolling_App1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "WmPEn1_Tb8SA",
        "outputId": "d29cf71f-1f8b-4ac6-8539-283bd1848f9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-754ecafc05d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mNN_Func_App1\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mNFB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'NN_Func_App1'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "\"\"\"\n",
        "Reduced script that covers:\n",
        "    --> rolling implementation for:\n",
        "        \n",
        "        i) Simple Neural Network with forward rates\n",
        "        ii) Simple LSTM-Model with forward rates\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.io as sio\n",
        "import multiprocessing as mp\n",
        "import os\n",
        "import time\n",
        "import statsmodels.api as sm\n",
        "from scipy.stats import t as tstat\n",
        "import shutil\n",
        "\n",
        "import NN_Func_App1 as NFB\n",
        "\n",
        "\n",
        "# User Functions\n",
        "\n",
        "\n",
        "def multProcessOwnExog(NNfunc, ncpus, _nMC, X, Xexog, Y, **kwargs):\n",
        "    try:\n",
        "        pool = mp.Pool(processes=ncpus)\n",
        "        output = [pool.apply_async(NNfunc, args=(X, Xexog, Y, no,),\n",
        "                                   kwds=kwargs)\n",
        "                  for no in range(_nMC)]\n",
        "        outputCons = [p.get(timeout=3000) for p in output]\n",
        "        pool.close()\n",
        "        pool.join()\n",
        "        time.sleep(1)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"Timed out, shutting pool down\")\n",
        "        pool.close()\n",
        "        pool.terminate()\n",
        "        time.sleep(1)\n",
        "\n",
        "    return outputCons\n",
        "\n",
        "\n",
        "def R2OOS(y_true, y_forecast):\n",
        "    import numpy as np\n",
        "\n",
        "    # Compute conidtional mean forecast\n",
        "    y_condmean = np.divide(y_true.cumsum(), (np.arange(y_true.size)+1))\n",
        "\n",
        "    # lag by one period\n",
        "    y_condmean = np.insert(y_condmean, 0, np.nan)\n",
        "    y_condmean = y_condmean[:-1] \n",
        "    y_condmean[np.isnan(y_forecast)] = np.nan \n",
        "\n",
        "    # Sum of Squared Resids\n",
        "    SSres = np.nansum(np.square(y_true-y_forecast))\n",
        "    SStot = np.nansum(np.square(y_true-y_condmean))\n",
        "\n",
        "    return 1-SSres/SStot\n",
        "\n",
        "\n",
        "def RSZ_Signif(y_true, y_forecast):\n",
        "\n",
        "    # Compute conidtional mean forecast\n",
        "    y_condmean = np.divide(y_true.cumsum(), (np.arange(y_true.size)+1))\n",
        "\n",
        "    # lag by one period\n",
        "    y_condmean = np.insert(y_condmean, 0, np.nan)\n",
        "    y_condmean = y_condmean[:-1]\n",
        "    # y_condmean[np.isnan(y_forecast)] = np.nan # ! NOt needed here in update\n",
        "\n",
        "    # Compute f-measure\n",
        "        # !!! According to paper Rpach Strauss... page 8-9 the last + should be -\n",
        "    f = np.square(y_true-y_condmean)-np.square(y_true-y_forecast)  \\\n",
        "        + np.square(y_condmean-y_forecast)\n",
        "\n",
        "    # Regress f on a constant\n",
        "    x = np.ones(np.shape(f))\n",
        "    model = sm.OLS(f, x, missing='drop', hasconst=True)\n",
        "    results = model.fit(cov_type='HAC', cov_kwds={'maxlags': 12})\n",
        "\n",
        "    return 1-tstat.cdf(results.tvalues[0], results.nobs-1)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # =========================================================================\n",
        "    #                           Settings\n",
        "    # =========================================================================\n",
        "\n",
        "    # Set True for testing, False otherwise. Reduces computational complexity.\n",
        "    # TestFlag is for development purposes only.\n",
        "    TestFlag = True\n",
        "    if TestFlag:\n",
        "        _nMC = 10  # Number of networks to train in parallel\n",
        "        _nAvg = 6  # Number of best networks to take for model averaging\n",
        "    else:\n",
        "        _nMC = 100\n",
        "        _nAvg = 10\n",
        "\n",
        "    OOS_Start = '1989-02-01'  # Date of RHS variable where to start OOS\n",
        "\n",
        "    HyperFreq = 2*24  # Frequency of hyper-parameter search # !!! DECREASED\n",
        "    NN_Params = {'Dropout': [0.1, 0.3, 0.5], 'l1l2': [0.01, 0.001]}\n",
        "    \n",
        "    # For LSTM\n",
        "    other_gen = {\"_len\": 12, \"_batch_top\": 32, \"_batch_bot\": 32}\n",
        "\n",
        "    # Computational Ressources: Determine Number of available cores\n",
        "    ncpus = mp.cpu_count()\n",
        "    print(\"CPU count is: \"+str(ncpus))\n",
        "\n",
        "    # Location for temporary model storage. Deleted upon completion.\n",
        "    dumploc_base = './trainingDumps_'\n",
        "\n",
        "    i = 0\n",
        "    path_established = False\n",
        "    while not path_established:\n",
        "        dumploc = dumploc_base+str(i)\n",
        "        try:\n",
        "            os.mkdir(dumploc)\n",
        "            print(\"Directory \", dumploc, \" Created \")\n",
        "            path_established = True\n",
        "        except FileExistsError:\n",
        "            print(\"Directory \", dumploc, \" Already exists\")\n",
        "            i += 1\n",
        "\n",
        "    # Set of models for training\n",
        "    #models = [NFB.NN3LayerExog, NFB.ElasticNet_Exog_Plain, NFB.NN1LayerEnsemExog]\n",
        "    #models = [NFB.NNForwardRun, NFB.NN3LayerExog, NFB.NN1LayerEnsemExog_2D, NFB.NN1LayerEnsemExog_3D]\n",
        "    #models = [NFB.NNForwardRun , NFB.NN1LayerEnsemExog_2D]\n",
        "    #models =  [NFB.NN3LayerExog, NFB.NNForwardRun, NFB.NN1LayerEnsemExog_2D]\n",
        "    #models = [NFB.NNForwardRun]\n",
        "    # Set of names to use for models. Same order as in list \"models\".\n",
        "    #modelnames = [\"NNForwardRun\", \"NN3LayerExog\", \"NN1LayerEnsemExog_2D\", \"NN1LayerEnsemExog_3D\"]\n",
        "    #modelnames = [\"NNForwardRun\", \"NN1LayerEnsemExog_2D\"]\n",
        "    #modelnames = [\"NN3LayerExog\", \"NNForwardFunction\", \"NN1LayerEnsemExog_2D\"]\n",
        "    #modelnames = [\"NNForwardFunction\"]\n",
        "    \n",
        "    #acrch_all = {\"NNForwardFunction\": [[32,16,8],[16,8],[8]]}\n",
        "    #arch_all = [[32,16,8],[16,8],[8]]\n",
        "    #archi = [32,16,8]\n",
        "\n",
        "    # =========================================================================\n",
        "    #                          Data Loading\n",
        "    # =========================================================================\n",
        "\n",
        "\n",
        "    ###############\n",
        "    ## Load in Data\n",
        "    \n",
        "    # Load data from github repository\n",
        "    _url = \"https://github.com/FrederikKober/Thesis/blob/700edaddeea6644c26bacaa31227762663385652/dataset1_2.xlsx?raw=true\"\n",
        "\n",
        "    # for index\n",
        "    #_idx = pd.read_excel(\"/home/freddy/Dropbox/Thesis_Final/prepared_data/dataset1_2.xlsx\", sheet_name=\"dataset1\", index_col=0)\n",
        "    _idx = pd.read_excel(_url, sheet_name=\"dataset1\", index_col=0)\n",
        "\n",
        "    # Excess Returns (Y) --> TxM --> T observations with M variables forecasted simultaneously\n",
        "    Y = np.array(_idx.iloc[:,:9]) \n",
        "    \n",
        "    # Forward rates (TxN) --> with N number of forward rates\n",
        "    Xexog = np.array(_idx.iloc[:,9:])\n",
        "    \n",
        "    # Macro data \n",
        "    #X = pd.read_excel(\"/home/freddy/Dropbox/Thesis_Final/prepared_data/dataset1_2.xlsx\", sheet_name=\"dataset2\", index_col=0)\n",
        "    X = pd.read_excel(_url, sheet_name=\"dataset2\", index_col=0)\n",
        "    _rpi = np.where(X.columns == \"RPI\")[0][0]\n",
        "    X = np.array(X.iloc[:,_rpi:])\n",
        "\n",
        "\n",
        "    #######################\n",
        "    ## Define Architectures\n",
        "    model_dict = {\"Run_LSTM_Generic\": [NFB.Run_LSTM_Generic, [[7,4],[5,2]], [\"_7_4\",\"_5_2\"]],\n",
        "                  \"NNForwardFunction\": [NFB.NNForwardRun, [[16,8],[8,4],[8]], [\"_16_8\", \"_8_4\", \"_8\"]]}\n",
        "    \n",
        "    \n",
        "    # =========================================================================\n",
        "    #                   Estimation\n",
        "    # =========================================================================\n",
        "\n",
        "\n",
        "    # Determine IS vs OS indices\n",
        "    _T = Xexog.shape[0]\n",
        "    tstart = np.argmax(_idx.index == OOS_Start)\n",
        "    OoS_indeces = range(tstart, int(_T))\n",
        "    # Number of outputs\n",
        "    _M = Y.shape[1]\n",
        "\n",
        "    if TestFlag:\n",
        "        OoS_indeces = OoS_indeces[:10]\n",
        "\n",
        "    VarSave = {}  # Storage dictionary for all results\n",
        "\n",
        "    # Loop over models\n",
        "    #for modelnum, modelfunc in enumerate(models): ## !! modelnum, modelfunc --> needs to spit out  names and functions\n",
        "    for function in model_dict:\n",
        "    \n",
        "        Y_forecast = np.full([_T, _nMC, _M], np.nan)\n",
        "        Y_forecast_agg = np.full([_T, _M], np.nan)\n",
        "        val_loss = np.full([_T, _nMC], np.nan)\n",
        "        #print(modelnames[modelnum]) # !! modelnum and modelnames\n",
        "\n",
        "\n",
        "        \n",
        "        #====================================================================#\n",
        "        # Model Case Distinction\n",
        "        #====================================================================#\n",
        "        \n",
        "        #######################\n",
        "        ## NNForwardFunction ##\n",
        "        \n",
        "        if function == 'NNForwardFunction': \n",
        "            # Loop over Model architectures \n",
        "            for _num, _arch in enumerate(model_dict[function][1]):\n",
        "                # Define\n",
        "                archi = _arch\n",
        "                modelname = function + model_dict[function][2][_num]\n",
        "                modelfunc = model_dict[function][0]\n",
        "                print(archi)\n",
        "            \n",
        "                j = 1\n",
        "                for i in OoS_indeces:\n",
        "    \n",
        "                    # Determine whether to perform fresh hyper-parameter search\n",
        "                    if (j == 1) or (j % HyperFreq == 0):\n",
        "                        refit = True\n",
        "                    else:\n",
        "                        refit = False\n",
        "                    j += 1\n",
        "    \n",
        "                    # Run model\n",
        "                    start = time.time()\n",
        "                    output = multProcessOwnExog(modelfunc, ncpus, _nMC, X[:i+1, :], \n",
        "                                                Xexog[:i+1, :], Y[:i+1, :],\n",
        "                                                dumploc=dumploc, params=NN_Params,\n",
        "                                                refit=refit, archi = archi)\n",
        "                    # Handle output\n",
        "                    val_loss[i, :] = np.array([output[k][1] for k in range(_nMC)])\n",
        "                    Y_forecast[i, :, :] = np.concatenate([output[k][0] for k\n",
        "                                                          in range(_nMC)], axis=0)\n",
        "                    tempsort = np.argsort(val_loss[i, :])\n",
        "                    ypredmean = np.mean(Y_forecast[i, tempsort[:_nAvg], :], axis=0)\n",
        "                    Y_forecast_agg[i, :] = ypredmean\n",
        "                    print(\"Obs No.: \", i, \" - Step Time: \", time.time() - start)\n",
        "\n",
        "                # Validation Loss\n",
        "                VarSave[\"ValLoss_\"+modelname] = val_loss # !! modelnames[modelnum]\n",
        "                \n",
        "                # Fitted / Forecasted Values (Averaged)\n",
        "                VarSave[\"Y_forecast_agg_\"+modelname] = Y_forecast_agg #  !! modelnames[modelnum]\n",
        "        \n",
        "                # Fitted / Forecasted Values (From models trained in parallel)\n",
        "                VarSave[\"Y_forecast_\"+modelname] = Y_forecast # !! modelnames[modelnum]\n",
        "        \n",
        "                # Mean Squared Error\n",
        "                VarSave[\"MSE_\"+modelname] = np.nanmean(np.square(Y-Y_forecast_agg), axis=0)  # !! modelnames[modelnum]\n",
        "        \n",
        "                # R2-00S\n",
        "                VarSave[\"R2OOS_\"+modelname] = np.array( # !! modelnames[modelnum]\n",
        "                    [R2OOS(Y[:, k], Y_forecast_agg[:, k]) for k in range(np.size(Y, axis=1))])\n",
        "        \n",
        "                print('R2OOS: ', VarSave[\"R2OOS_\"+modelname]) # !! modelnames[modelnum]\n",
        "        \n",
        "                # Rapach, Strauss, Zhou (2010) - Significance R^2\n",
        "                VarSave[\"R2OOS_pval_\"+modelname] = \\\n",
        "                    np.array([RSZ_Signif(Y[:, k], Y_forecast_agg[:, k])\n",
        "                              for k in range(np.size(Y, axis=1))])\n",
        "          \n",
        "\n",
        "        ######################################################################\n",
        "        ######################################################################\n",
        "        \n",
        "        ## Run_LSTM_Generic ##\n",
        "        \n",
        "        elif function == 'Run_LSTM_Generic': \n",
        "            # Defined above\n",
        "            #other = {\"_len\": 3, \"_batch_top\": 32, \"_batch_bot\": 32}\n",
        "\n",
        "       \n",
        "            # Loop over Model architectures \n",
        "            for _num, _arch in enumerate(model_dict[function][1]):\n",
        "                # Define\n",
        "                archi = _arch\n",
        "                modelname = function + model_dict[function][2][_num]\n",
        "                modelfunc = model_dict[function][0]\n",
        "                print(archi)\n",
        "            \n",
        "                j = 1\n",
        "                for i in OoS_indeces:\n",
        "    \n",
        "                    # Determine whether to perform fresh hyper-parameter search\n",
        "                    if (j == 1) or (j % HyperFreq == 0):\n",
        "                        refit = True\n",
        "                    else:\n",
        "                        refit = False\n",
        "                    j += 1\n",
        "    \n",
        "                    # Run model\n",
        "                    start = time.time()\n",
        "                    output = multProcessOwnExog(modelfunc, ncpus, _nMC, X[:i+1, :], \n",
        "                                                Xexog[:i+1, :], Y[:i+1, :],\n",
        "                                                dumploc=dumploc, params=NN_Params,\n",
        "                                                refit=refit, archi = archi, other_gen = other_gen) # !!! HERE\n",
        "                    # Handle output\n",
        "                    val_loss[i, :] = np.array([output[k][1] for k in range(_nMC)])\n",
        "                    Y_forecast[i, :, :] = np.concatenate([output[k][0] for k\n",
        "                                                          in range(_nMC)], axis=0)\n",
        "                    tempsort = np.argsort(val_loss[i, :])\n",
        "                    ypredmean = np.mean(Y_forecast[i, tempsort[:_nAvg], :], axis=0)\n",
        "                    Y_forecast_agg[i, :] = ypredmean\n",
        "                    print(\"Obs No.: \", i, \" - Step Time: \", time.time() - start)\n",
        "\n",
        "                # Validation Loss\n",
        "                VarSave[\"ValLoss_\"+modelname] = val_loss # !! modelnames[modelnum]\n",
        "                \n",
        "                # Fitted / Forecasted Values (Averaged)\n",
        "                VarSave[\"Y_forecast_agg_\"+modelname] = Y_forecast_agg #  !! modelnames[modelnum]\n",
        "        \n",
        "                # Fitted / Forecasted Values (From models trained in parallel)\n",
        "                VarSave[\"Y_forecast_\"+modelname] = Y_forecast # !! modelnames[modelnum]\n",
        "        \n",
        "                # Mean Squared Error\n",
        "                VarSave[\"MSE_\"+modelname] = np.nanmean(np.square(Y-Y_forecast_agg), axis=0)  # !! modelnames[modelnum]\n",
        "        \n",
        "                # R2-00S\n",
        "                VarSave[\"R2OOS_\"+modelname] = np.array( # !! modelnames[modelnum]\n",
        "                    [R2OOS(Y[:, k], Y_forecast_agg[:, k]) for k in range(np.size(Y, axis=1))])\n",
        "        \n",
        "                print('R2OOS: ', VarSave[\"R2OOS_\"+modelname]) # !! modelnames[modelnum]\n",
        "        \n",
        "                # Rapach, Strauss, Zhou (2010) - Significance R^2\n",
        "                VarSave[\"R2OOS_pval_\"+modelname] = \\\n",
        "                    np.array([RSZ_Signif(Y[:, k], Y_forecast_agg[:, k])\n",
        "                              for k in range(np.size(Y, axis=1))])\n",
        "                                 \n",
        "                \n",
        "        else:\n",
        "            raise Exception(\"Model does not match any known case.\")\n",
        "\n",
        "\n",
        "        savesuccess_flag = False\n",
        "        while not savesuccess_flag:\n",
        "            # Save new result to SOA file\n",
        "            try:\n",
        "                VarSaveSOA = sio.loadmat('ModelComparison_Rolling_SOA.mat')\n",
        "                VarSaveSOA.update(VarSave)\n",
        "                sio.savemat('ModelComparison_Rolling_SOA.mat', VarSaveSOA)\n",
        "                savesuccess_flag = True\n",
        "                print('Updated SOA file')\n",
        "            except FileNotFoundError:\n",
        "                sio.savemat('ModelComparison_Rolling_SOA.mat', VarSave)\n",
        "                savesuccess_flag = True\n",
        "                print('Created new SOA file')\n",
        "\n",
        "    # Delete Dumploc\n",
        "    try:\n",
        "        shutil.rmtree(dumploc)\n",
        "        print('Removed dir: '+dumploc+' succesfully')\n",
        "    except FileNotFoundError:\n",
        "        print('Directory: '+dumploc+' could not be removed')"
      ]
    }
  ]
}